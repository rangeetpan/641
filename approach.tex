\section{Approach}
\label{sec:approach}
In this section, we have proposed a comprehensive approach to address the discussed problem. In our approach, at first we have proposed a validation technique and utilized that to achieve accountability of a DNN model. In the \S\ref{sec:background}, we have discussed the forward and backward propagation. In the two-step learning process, random initialization plays a crucial role in model validation. In Figure \ref{fig:rq5}, a traditional DNN model iteratively chooses the input. The choice can be a single input at a time or a group of inputs. Three known parameters require random initialization i.e., seed, weight, and bias \cite{sutskever2013importance}. Our hypothesis in this study states that \emph{$H_0$: Knowing the distribution of the random initialized parameter can provide the distribution of the output parameter, e.g., accuracy metric.} Based on this hypothesis, we select the operations that require random initialization. Then, with the known distribution, we perform the model operations as follows.
\begin{equation}
f(\sum_{\chi}{W_iX_i+B}), \chi\sim D(\mu, \sigma^2)
\end{equation}
In the equation above, the traditional dense operation has been depicted as an example, where, $W_i$, $X_i$, $B_i$, $f()$, and $D$ represents the weight, input, bias, the activation function, and a unknown distribution of the operations respectively that require random initialization. The output of this learning process will be an interval of value rather than a single concrete value. In Figure \ref{fig:rq5}, we have depicted a similar scenario that includes the learning of the distribution, which results in an interval reported as "[Low, High]". The interval is similar to any algorithmic evaluation with the best-case and worst-case scenario. 
The contribution of this proposed approach in programming language and accountability has been described as follows.
\paragraph{\textbf{Accountability.}} According to the study \cite{veale2018fairness}, accountability in decision making represents the explanation about the "ongoing strategy". From the \S\ref{sec:motivation}, we have found that a single model structure can provide different decision-making capabilities due to the assertion of the probabilistic distribution in the initialization process. The prior work \cite{sampson2014expressing} has already demostrated that assertion based specification language can achieve accountability by reasoning about programs that behave randomly. In our proposed approach, we learn the unknown distribution of the initialization parameter. Then, we interpret the learning process by providing an interval of output metric rather than a single value that changes with every iteration of the learning process. This approach will help the end-users to hold a model accountable in terms of the contract made between the model structure and the predicted output.
\paragraph{\textbf{Programming Language.}} This approach includes the validation framework from the learned distribution. We have proposed an assertion mechanism that verify the operation of the distribution and the input to restrict the learning process to go beyond the desired interval of output metrics. We propose \emph{ADNN}, a specification language that restricts a learning process from a pair $(f,\nu)$, where $f$ and $\nu$ denotes the learning process and the specification provided by the user. An example of the programming language is depicted as below.
\begin{lstlisting}[language=Python, caption=Accountable specification language]
@adnn(0.95>accuracy>0.65)
f(input_image, ....)
\\Learning operations
\end{lstlisting}