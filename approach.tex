\section{Approach}
\label{sec:approach}
In this section, we have discussed the proposed approach to address the problem. We have divided the approach into the validation technique and how this validation will help in gaining accountability in a DNN model. In the \S\ref{sec:background}, we have discussed the forward and backward propagation. In the two-step learning process, random initialization plays a crucial role in model validation. In Figure \ref{fig:rq5}, a traditional DNN model iteratively chooses the input, and the choice can be a single input at a time or a group of inputs. Three known parameters require random initialization, seed, weight, and bias \cite{sutskever2013importance}. Our hypothesis in this study states that \emph{$H_0$: Knowing the distribution of the random initialized parameter can provide the distribution of the output parameter, e.g., accuracy metric.} Based on the hypothesis, we select the operations that require random initialization. Then, with the known distribution, we perform the model operations as follows.
\begin{equation}
f(\sum_{\chi}{W_iX_i+B}), \chi\sim D(\mu, \sigma^2)
\end{equation}
In the equation above, the traditional dense operation has been depicted as an example, where, $W_i$, $X_i$, $B_i$, $f()$, and $D$ represents the weight, input, bias, the activation operation, and unknown distribution of the operations that require random initialization. The output of this learning process will be an interval of value rather than a single concrete value. In Figure \ref{fig:rq5}, we have depicted a similar scenario that includes the learning of the distribution, which results in an interval reported as "[Low, High]." The interval is similar to any algorithmic evaluation with the best case and worst-case scenario. 
The contribution of this proposed approach in programming language and accountability has been described below.
\paragraph{Accountability.} According to the \cite{veale2018fairness}, accountability in decision making represents the explanation about the "ongoing strategy." From the \S\ref{sec:motivation}, we have found that a single model structure can provide different decision-making capabilities due to the assertion of the probabilistic distribution in the initialization process. The proposed approach, learn the unknown distribution of the initialization parameter and explain the learning process by providing an interval of output metric rather than a single value that changes with every iteration of the learning process. This approach will help the end-users to hold a model accountable in terms of the contract made between the model structure and the predicted output.
\paragraph{Programming Language.} This approach includes the validation framework from the learned distribution. We have proposed an assertion structure that checks the operation of the distribution and the input to restrict the model training process to go beyond the desired range of output metrics. We propose $A^2$, a specification language that restricts a learning process from a pair $(f,\nu)$, where $f$, $\nu$ denotes the learning process and the specification provided the user. An example of the programming language is depicted below.
\begin{lstlisting}[language=Python, caption=Accountable specification language]
@a2(0.95>accuracy>0.65)
f(input_image, ....)
\\Learning operations
\end{lstlisting}