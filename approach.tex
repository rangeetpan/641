\section{Approach}
\label{sec:approach}
In this section, we have discussed the proposed approach to address the problem. We have divided the approach into the validation technique and how this validation will help in gaining accountability in a DNN model. In the \S\ref{sec:background}, we have discussed the forward and backward propagation. In the two-step learning process, random initialization plays a crucial role in the model validation. In Figure \ref{fig:rq5}, a traditional DNN model iteratively chooses the input and the choice can be a single input at a time or a group of inputs. There are three known parameters that requires random intialization, seed, weight, and bias \cite{sutskever2013importance}. Our hypothesis in this study states that \emph{$H_0$: Knowing the distributation of the random initialized parameter can provide the distribution of the output parameter e.g., accuracy metric.} Based on the hypothesis, we select the operations that require the random intialization. Then, with the known distributation, we perform the model operations as follows.
\begin{equation}
f(\sum_{D}{W_iX_i+B}), D\sim()
\end{equation}

